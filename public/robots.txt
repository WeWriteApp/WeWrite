# Robots.txt for WeWrite - The Social Wiki Where Every Page is a Fundraiser
# https://wewrite.app

User-agent: *
Allow: /

# Allow all search engines to crawl the site
Allow: /auth/
Allow: /trending
Allow: /leaderboard
Allow: /groups
Allow: /users
Allow: /search

# Disallow private/sensitive areas
Disallow: /api/
Disallow: /admin/
Disallow: /_next/
Disallow: /private/
Disallow: /user/*/private
Disallow: /group/*/private

# Allow crawling of pages and user profiles
Allow: /page/
Allow: /user/
Allow: /group/

# Sitemap locations
Sitemap: https://wewrite.app/sitemap.xml
Sitemap: https://wewrite.app/sitemap-index.xml
Sitemap: https://wewrite.app/api/sitemap-pages
Sitemap: https://wewrite.app/api/sitemap-users
Sitemap: https://wewrite.app/api/sitemap-groups

# Crawl delay (optional - be respectful to server resources)
Crawl-delay: 1

# Specific rules for major search engines
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: Slurp
Allow: /
Crawl-delay: 1

# Block any malicious bots
User-agent: BadBot
Disallow: /

User-agent: SemrushBot
Allow: /

User-agent: AhrefsBot
Allow: /

User-agent: MJ12bot
Allow: /
